{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3db6949e",
      "metadata": {
        "id": "3db6949e"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql.functions import udf\n",
        "from pyspark.ml.linalg import SparseVector, VectorUDT\n",
        "from pyspark.ml.feature import PCA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e61b88d2",
      "metadata": {
        "id": "e61b88d2"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "\n",
        "spark = SparkSession.builder \\\n",
        "    .getOrCreate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c62adc50",
      "metadata": {
        "id": "c62adc50",
        "outputId": "14dc2b01-37a6-403f-9e52-f1c5ad45afba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;36mbin\u001b[0m@       \u001b[01;34mdev\u001b[0m/     \u001b[01;34mhome\u001b[0m/   \u001b[01;34mlost+found\u001b[0m/  \u001b[01;34mopt\u001b[0m/   \u001b[01;34mrun\u001b[0m/   \u001b[01;34msys\u001b[0m/  \u001b[01;34mvar\u001b[0m/\r\n",
            "\u001b[01;34mboot\u001b[0m/      \u001b[01;34metc\u001b[0m/     \u001b[01;36mlib\u001b[0m@    \u001b[01;34mmedia\u001b[0m/       \u001b[01;34mproc\u001b[0m/  \u001b[01;36msbin\u001b[0m@  \u001b[30;42mtmp\u001b[0m/\r\n",
            "copyright  \u001b[01;34mhadoop\u001b[0m/  \u001b[01;36mlib64\u001b[0m@  \u001b[01;34mmnt\u001b[0m/         \u001b[01;34mroot\u001b[0m/  \u001b[01;34msrv\u001b[0m/   \u001b[01;34musr\u001b[0m/\r\n"
          ]
        }
      ],
      "source": [
        "%ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c6cdc1f6",
      "metadata": {
        "id": "c6cdc1f6",
        "outputId": "d51ef19b-381c-482b-bb14-9ff2a5696f45"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        }
      ],
      "source": [
        "expression_df = spark.read.parquet(\"gs://medical-data-for-project/huggingface.co/datasets/vevotx/Tahoe-100M/resolve/main/data/\")\n",
        "cell_line_df = spark.read.parquet(\"gs://medical-data-for-project/huggingface.co/datasets/vevotx/Tahoe-100M/resolve/main/meta_data/cell_line_metadata.parquet\")\n",
        "drug_df = spark.read.parquet(\"gs://medical-data-for-project/huggingface.co/datasets/vevotx/Tahoe-100M/resolve/main/meta_data/drug_metadata.parquet\")\n",
        "gene_df = spark.read.parquet(\"gs://medical-data-for-project/huggingface.co/datasets/vevotx/Tahoe-100M/resolve/main/meta_data/gene_metadata.parquet\")\n",
        "observation_df = spark.read.parquet(\"gs://medical-data-for-project/huggingface.co/datasets/vevotx/Tahoe-100M/resolve/main/meta_data/obs_metadata.parquet\")\n",
        "sample_df = spark.read.parquet(\"gs://medical-data-for-project/huggingface.co/datasets/vevotx/Tahoe-100M/resolve/main/meta_data/sample_metadata.parquet\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "512ab225",
      "metadata": {
        "id": "512ab225",
        "outputId": "2b09a8d4-bc7e-47eb-e721-17bdd02f4902"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['genes', 'expressions', 'drug', 'sample', 'BARCODE_SUB_LIB_ID', 'cell_line_id', 'moa-fine', 'canonical_smiles', 'pubchem_cid', 'plate']\n",
            "['cell_name', 'Cell_ID_DepMap', 'Cell_ID_Cellosaur', 'Organ', 'Driver_Gene_Symbol', 'Driver_VarZyg', 'Driver_VarType', 'Driver_ProtEffect_or_CdnaEffect', 'Driver_Mech_InferDM', 'Driver_GeneType_DM']\n",
            "['drug', 'targets', 'moa-broad', 'moa-fine', 'human-approved', 'clinical-trials', 'gpt-notes-approval', 'canonical_smiles', 'pubchem_cid']\n",
            "['gene_symbol', 'ensembl_id', 'token_id']\n",
            "['plate', 'BARCODE_SUB_LIB_ID', 'sample', 'gene_count', 'tscp_count', 'mread_count', 'drugname_drugconc', 'drug', 'cell_line', 'sublibrary', 'BARCODE', 'pcnt_mito', 'S_score', 'G2M_score', 'phase', 'pass_filter', 'cell_name', '__index_level_0__']\n",
            "['sample', 'plate', 'mean_gene_count', 'mean_tscp_count', 'mean_mread_count', 'mean_pcnt_mito', 'drug', 'drugname_drugconc']\n"
          ]
        }
      ],
      "source": [
        "print(expression_df.columns)\n",
        "print(cell_line_df.columns)\n",
        "print(drug_df.columns)\n",
        "print(gene_df.columns)\n",
        "print(observation_df.columns)\n",
        "print(sample_df.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "023ef190",
      "metadata": {
        "id": "023ef190",
        "outputId": "5f70ee0c-002b-4f44-ccc1-a26fc800af4f"
      },
      "outputs": [
        {
          "ename": "AnalysisException",
          "evalue": "[AMBIGUOUS_REFERENCE] Reference `moa-fine` is ambiguous, could be: [`moa-fine`, `moa-fine`].",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[8], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mexpression_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcell_line_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexpression_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcell_line_id\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcell_line_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCell_ID_Cellosaur\u001b[49m\u001b[43m)\u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msample\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdrug_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdrug\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m\\\u001b[49m\n\u001b[0;32m----> 4\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgenes\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mexpressions\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmoa-fine\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcanonical_smiles\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdrug\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msample\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdrugname_drugconc\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmoa-broad\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcell_name\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43morgan\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mDriver_Gene_Symbol\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mDriver_Mech_InferDM\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mDriver_GeneType_DM\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmean_pcnt_mito\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m#            Expr table                                                                Drug table,                         Cell_name,                                                                             sample\u001b[39;00m\n",
            "File \u001b[0;32m/usr/lib/spark/python/pyspark/sql/dataframe.py:3229\u001b[0m, in \u001b[0;36mDataFrame.select\u001b[0;34m(self, *cols)\u001b[0m\n\u001b[1;32m   3184\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mselect\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39mcols: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mColumnOrName\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataFrame\u001b[39m\u001b[38;5;124m\"\u001b[39m:  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   3185\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Projects a set of expressions and returns a new :class:`DataFrame`.\u001b[39;00m\n\u001b[1;32m   3186\u001b[0m \n\u001b[1;32m   3187\u001b[0m \u001b[38;5;124;03m    .. versionadded:: 1.3.0\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3227\u001b[0m \u001b[38;5;124;03m    +-----+---+\u001b[39;00m\n\u001b[1;32m   3228\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 3229\u001b[0m     jdf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jcols\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcols\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3230\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m DataFrame(jdf, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msparkSession)\n",
            "File \u001b[0;32m/usr/lib/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
            "File \u001b[0;32m/usr/lib/spark/python/pyspark/errors/exceptions/captured.py:185\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    181\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[1;32m    184\u001b[0m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[0;32m--> 185\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
            "\u001b[0;31mAnalysisException\u001b[0m: [AMBIGUOUS_REFERENCE] Reference `moa-fine` is ambiguous, could be: [`moa-fine`, `moa-fine`]."
          ]
        }
      ],
      "source": [
        "df = expression_df.join(cell_line_df, expression_df.cell_line_id == cell_line_df.Cell_ID_Cellosaur)\\\n",
        "    .join(sample_df, \"sample\")\\\n",
        "    .join(drug_df, \"drug\")\\\n",
        "    .select('genes', 'expressions', 'moa-fine', 'canonical_smiles', 'drug', 'sample', 'drugname_drugconc', 'moa-broad', 'cell_name', 'organ', 'Driver_Gene_Symbol', 'Driver_Mech_InferDM', 'Driver_GeneType_DM', 'mean_pcnt_mito')\n",
        "#            Expr table                                                                Drug table,                         Cell_name,                                                                             sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "69ba4042",
      "metadata": {
        "id": "69ba4042"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql.functions import col\n",
        "\n",
        "# Aliases\n",
        "expr_df = expression_df.alias(\"expr\")\n",
        "cell_df = cell_line_df.alias(\"cell\")\n",
        "sample_df_ = sample_df.alias(\"sample\")\n",
        "drug_df_ = drug_df.alias(\"drug\")\n",
        "\n",
        "df = (\n",
        "    expr_df.join(cell_df, col(\"expr.cell_line_id\") == col(\"cell.Cell_ID_Cellosaur\"))\n",
        "          .join(sample_df_, col(\"expr.sample\") == col(\"sample.sample\"))\n",
        "          .join(drug_df_, col(\"expr.drug\") == col(\"drug.drug\"))\n",
        "          .select(\n",
        "              col(\"expr.genes\").alias(\"genes\"),\n",
        "              col(\"expr.expressions\").alias(\"expressions\"),\n",
        "              col(\"drug.`moa-fine`\").alias(\"moa-fine\"),\n",
        "              col(\"drug.canonical_smiles\").alias(\"canonical_smiles\"),\n",
        "              col(\"expr.drug\").alias(\"drug\"),\n",
        "              col(\"expr.sample\").alias(\"sample\"),\n",
        "              col(\"drug.`moa-broad`\").alias(\"moa-broad\"),\n",
        "              col(\"cell.cell_name\").alias(\"cell_name\"),\n",
        "              col(\"cell.organ\").alias(\"organ\"),\n",
        "              col(\"cell.Driver_Gene_Symbol\").alias(\"Driver_Gene_Symbol\"),\n",
        "              col(\"cell.Driver_Mech_InferDM\").alias(\"Driver_Mech_InferDM\"),\n",
        "              col(\"cell.Driver_GeneType_DM\").alias(\"Driver_GeneType_DM\"),\n",
        "              col(\"sample.drugname_drugconc\").alias(\"drugname_drugconc\"),\n",
        "              col(\"sample.mean_pcnt_mito\").alias(\"mean_pcnt_mito\")\n",
        "          )\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2a21bf00",
      "metadata": {
        "id": "2a21bf00",
        "outputId": "a296be78-18c9-429b-ceaf-f79e55ad7d6d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Stage 24:>                                                         (0 + 1) / 1]\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------+--------+\n",
            "|moa-fine|   Organ|\n",
            "+--------+--------+\n",
            "| unclear|   Bowel|\n",
            "| unclear|   Bowel|\n",
            "| unclear|   Bowel|\n",
            "| unclear|   Bowel|\n",
            "| unclear|   Bowel|\n",
            "| unclear|   Bowel|\n",
            "| unclear|  Breast|\n",
            "| unclear|  Breast|\n",
            "| unclear|  Breast|\n",
            "| unclear|  Breast|\n",
            "| unclear|  Breast|\n",
            "| unclear|  Breast|\n",
            "| unclear|  Breast|\n",
            "| unclear|  Breast|\n",
            "| unclear|  Breast|\n",
            "| unclear|  Breast|\n",
            "| unclear|  Breast|\n",
            "| unclear|  Breast|\n",
            "| unclear|Pancreas|\n",
            "| unclear|Pancreas|\n",
            "+--------+--------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r",
            "                                                                                \r"
          ]
        }
      ],
      "source": [
        "df.select(\"moa-fine\", \"Organ\").show(20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3e648930",
      "metadata": {
        "id": "3e648930",
        "outputId": "d5fbea2c-8301-4624-bb58-9a4377207046"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+------------+-----------------+------+\n",
            "|cell_line_id|Cell_ID_Cellosaur| Organ|\n",
            "+------------+-----------------+------+\n",
            "|   CVCL_0546|        CVCL_0546| Bowel|\n",
            "|   CVCL_0546|        CVCL_0546| Bowel|\n",
            "|   CVCL_0546|        CVCL_0546| Bowel|\n",
            "|   CVCL_0546|        CVCL_0546| Bowel|\n",
            "|   CVCL_0546|        CVCL_0546| Bowel|\n",
            "|   CVCL_0546|        CVCL_0546| Bowel|\n",
            "|   CVCL_0179|        CVCL_0179|Breast|\n",
            "|   CVCL_0179|        CVCL_0179|Breast|\n",
            "|   CVCL_0179|        CVCL_0179|Breast|\n",
            "|   CVCL_0179|        CVCL_0179|Breast|\n",
            "+------------+-----------------+------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df = expression_df.join(cell_line_df, expression_df.cell_line_id == cell_line_df.Cell_ID_Cellosaur)\n",
        "df.select(\"cell_line_id\", \"Cell_ID_Cellosaur\", \"Organ\").show(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7e69d1e8",
      "metadata": {
        "id": "7e69d1e8",
        "outputId": "44ad76a6-7c81-4c0a-8a07-bd62d11594a0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Stage 12:==============================================>           (4 + 1) / 5]\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------------------+\n",
            "|               Organ|\n",
            "+--------------------+\n",
            "|                Skin|\n",
            "|            Pancreas|\n",
            "|              Uterus|\n",
            "|           CNS/Brain|\n",
            "|              Cervix|\n",
            "|               Bowel|\n",
            "|                Lung|\n",
            "|   Esophagus/Stomach|\n",
            "|               Liver|\n",
            "|              Breast|\n",
            "|Peripheral Nervou...|\n",
            "|              Kidney|\n",
            "|Bladder/Urinary T...|\n",
            "+--------------------+\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r",
            "                                                                                \r"
          ]
        }
      ],
      "source": [
        "df.select(\"Organ\").distinct().show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "55280dac",
      "metadata": {
        "id": "55280dac",
        "outputId": "48f2aa28-b001-4326-892e-41d310b0e61e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['genes',\n",
              " 'expressions',\n",
              " 'drug',\n",
              " 'sample',\n",
              " 'BARCODE_SUB_LIB_ID',\n",
              " 'cell_line_id',\n",
              " 'moa-fine',\n",
              " 'canonical_smiles',\n",
              " 'pubchem_cid',\n",
              " 'plate']"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7233ab89",
      "metadata": {
        "id": "7233ab89",
        "outputId": "32aa698c-d824-4c6f-ec61-de043ee1d246"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- gene_symbol: string (nullable = true)\n",
            " |-- ensembl_id: string (nullable = true)\n",
            " |-- token_id: long (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "gene_df.printSchema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a3181fca",
      "metadata": {
        "id": "a3181fca",
        "outputId": "12beb7db-47de-4af9-aae0-3ed9bdda36ac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['plate', 'BARCODE_SUB_LIB_ID', 'sample', 'gene_count', 'tscp_count', 'mread_count', 'drugname_drugconc', 'drug', 'cell_line', 'sublibrary', 'BARCODE', 'pcnt_mito', 'S_score', 'G2M_score', 'phase', 'pass_filter', 'cell_name', '__index_level_0__']\n"
          ]
        }
      ],
      "source": [
        "print(observation_df.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "695004cf",
      "metadata": {
        "id": "695004cf",
        "outputId": "3880c87b-c183-458c-de60-a33879f64d9a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "data": {
            "text/plain": [
              "62710"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "gene_df.select(\"*\").distinct().count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b122a8cb",
      "metadata": {
        "id": "b122a8cb"
      },
      "outputs": [],
      "source": [
        "def make_sparse_vector(genes, expressions):\n",
        "    if genes is None or expressions is None:\n",
        "        return SparseVector(63000, {})\n",
        "    return SparseVector(63000, dict(zip(genes, expressions)))\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "089034e3",
      "metadata": {
        "id": "089034e3"
      },
      "outputs": [],
      "source": [
        "make_sparse_vector_udf = udf(make_sparse_vector, VectorUDT())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b4cf913a",
      "metadata": {
        "id": "b4cf913a"
      },
      "outputs": [],
      "source": [
        "df = df.withColumn(\"features\", make_sparse_vector_udf(\"Genes\", \"Expressions\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "32dcdac7",
      "metadata": {
        "id": "32dcdac7"
      },
      "outputs": [],
      "source": [
        "pca = PCA(k=256, inputCol=\"features\", outputCol=\"pca_features\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9a2376a2",
      "metadata": {
        "id": "9a2376a2",
        "outputId": "d3abdeaf-8884-4efd-f441-50aa538b34df"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "25/04/17 23:16:09 WARN RowMatrix: 63000 columns will require at least 31752 megabytes of memory!\n",
            "25/04/17 23:27:00 WARN YarnAllocator: Container from a bad node: container_1744839335032_0010_01_000010 on host: big-data-cluster-w-1.us-central1-a.c.excellent-math-456021-s0.internal. Exit status: 143. Diagnostics: [2025-04-17 23:27:00.202]Container killed on request. Exit code is 143\n",
            "[2025-04-17 23:27:00.202]Container exited with a non-zero exit code 143. \n",
            "[2025-04-17 23:27:00.203]Killed by external signal\n",
            ".\n",
            "25/04/17 23:27:00 ERROR YarnScheduler: Lost executor 9 on big-data-cluster-w-1.us-central1-a.c.excellent-math-456021-s0.internal: Container from a bad node: container_1744839335032_0010_01_000010 on host: big-data-cluster-w-1.us-central1-a.c.excellent-math-456021-s0.internal. Exit status: 143. Diagnostics: [2025-04-17 23:27:00.202]Container killed on request. Exit code is 143\n",
            "[2025-04-17 23:27:00.202]Container exited with a non-zero exit code 143. \n",
            "[2025-04-17 23:27:00.203]Killed by external signal\n",
            ".\n",
            "25/04/17 23:27:00 WARN TaskSetManager: Lost task 3.0 in stage 30.0 (TID 3420) (big-data-cluster-w-1.us-central1-a.c.excellent-math-456021-s0.internal executor 9): ExecutorLostFailure (executor 9 exited caused by one of the running tasks) Reason: Container from a bad node: container_1744839335032_0010_01_000010 on host: big-data-cluster-w-1.us-central1-a.c.excellent-math-456021-s0.internal. Exit status: 143. Diagnostics: [2025-04-17 23:27:00.202]Container killed on request. Exit code is 143\n",
            "[2025-04-17 23:27:00.202]Container exited with a non-zero exit code 143. \n",
            "[2025-04-17 23:27:00.203]Killed by external signal\n",
            ".\n",
            "25/04/17 23:27:00 WARN YarnSchedulerBackend$YarnSchedulerEndpoint: Requesting driver to remove executor 9 for reason Container from a bad node: container_1744839335032_0010_01_000010 on host: big-data-cluster-w-1.us-central1-a.c.excellent-math-456021-s0.internal. Exit status: 143. Diagnostics: [2025-04-17 23:27:00.202]Container killed on request. Exit code is 143\n",
            "[2025-04-17 23:27:00.202]Container exited with a non-zero exit code 143. \n",
            "[2025-04-17 23:27:00.203]Killed by external signal\n",
            ".\n",
            "25/04/17 23:48:45 WARN YarnAllocator: Container from a bad node: container_1744839335032_0010_01_000008 on host: big-data-cluster-w-0.us-central1-a.c.excellent-math-456021-s0.internal. Exit status: 143. Diagnostics: [2025-04-17 23:48:45.400]Container killed on request. Exit code is 143\n",
            "[2025-04-17 23:48:45.400]Container exited with a non-zero exit code 143. \n",
            "[2025-04-17 23:48:45.400]Killed by external signal\n",
            ".\n",
            "25/04/17 23:48:45 WARN YarnSchedulerBackend$YarnSchedulerEndpoint: Requesting driver to remove executor 7 for reason Container from a bad node: container_1744839335032_0010_01_000008 on host: big-data-cluster-w-0.us-central1-a.c.excellent-math-456021-s0.internal. Exit status: 143. Diagnostics: [2025-04-17 23:48:45.400]Container killed on request. Exit code is 143\n",
            "[2025-04-17 23:48:45.400]Container exited with a non-zero exit code 143. \n",
            "[2025-04-17 23:48:45.400]Killed by external signal\n",
            ".\n",
            "25/04/17 23:48:45 ERROR YarnScheduler: Lost executor 7 on big-data-cluster-w-0.us-central1-a.c.excellent-math-456021-s0.internal: Container from a bad node: container_1744839335032_0010_01_000008 on host: big-data-cluster-w-0.us-central1-a.c.excellent-math-456021-s0.internal. Exit status: 143. Diagnostics: [2025-04-17 23:48:45.400]Container killed on request. Exit code is 143\n",
            "[2025-04-17 23:48:45.400]Container exited with a non-zero exit code 143. \n",
            "[2025-04-17 23:48:45.400]Killed by external signal\n",
            ".\n",
            "25/04/17 23:48:45 WARN TaskSetManager: Lost task 11.0 in stage 30.0 (TID 3429) (big-data-cluster-w-0.us-central1-a.c.excellent-math-456021-s0.internal executor 7): ExecutorLostFailure (executor 7 exited caused by one of the running tasks) Reason: Container from a bad node: container_1744839335032_0010_01_000008 on host: big-data-cluster-w-0.us-central1-a.c.excellent-math-456021-s0.internal. Exit status: 143. Diagnostics: [2025-04-17 23:48:45.400]Container killed on request. Exit code is 143\n",
            "[2025-04-17 23:48:45.400]Container exited with a non-zero exit code 143. \n",
            "[2025-04-17 23:48:45.400]Killed by external signal\n",
            ".\n",
            "[Stage 30:>                                                     (12 + 4) / 3389]\r"
          ]
        }
      ],
      "source": [
        "pca_model = pca.fit(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4830c648",
      "metadata": {
        "id": "4830c648"
      },
      "outputs": [],
      "source": [
        "df_pca = pca_model.transform(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d15fd8b8",
      "metadata": {
        "id": "d15fd8b8"
      },
      "outputs": [],
      "source": [
        "df_pca.select(\"pca_features\").show(10, truncate=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3d7c86f9",
      "metadata": {
        "id": "3d7c86f9"
      },
      "outputs": [],
      "source": [
        "df_pca.columns()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "04aad99b",
      "metadata": {
        "id": "04aad99b"
      },
      "outputs": [],
      "source": [
        "from pyspark.mllib.linalg.distributed import RowMatrix\n",
        "\n",
        "# Convert to RDD[Vector] â€” compatible with both DenseVector and SparseVector\n",
        "rdd = df.select(\"features\").rdd.map(lambda row: row['features'])\n",
        "\n",
        "# Create a RowMatrix\n",
        "mat = RowMatrix(rdd)\n",
        "\n",
        "# Compute top-k SVD (no U if not needed)\n",
        "svd = mat.computeSVD(k=50, computeU=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7a996dec",
      "metadata": {
        "id": "7a996dec"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql.functions import udf\n",
        "from pyspark.sql.types import ArrayType, DoubleType\n",
        "from pyspark.ml.linalg import VectorUDT\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "V = np.array(svd.V.toArray())  # shape: (original_dim, k)\n",
        "V_broadcast = spark.sparkContext.broadcast(V)\n",
        "\n",
        "@udf(ArrayType(DoubleType()))\n",
        "def project_sparse(vec):\n",
        "    return np.dot(vec.toArray(), V_broadcast.value).tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9c7f9028",
      "metadata": {
        "id": "9c7f9028"
      },
      "outputs": [],
      "source": [
        "df_reduced = df.withColumn(\"reduced_features\", project_sparse(\"features\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1a5bd523",
      "metadata": {
        "id": "1a5bd523"
      },
      "outputs": [],
      "source": [
        "from pyspark.ml.linalg import Vectors\n",
        "from pyspark.sql.functions import udf\n",
        "\n",
        "@udf(VectorUDT())\n",
        "def to_dense_vector(arr):\n",
        "    return Vectors.dense(arr)\n",
        "\n",
        "df_reduced = df_reduced.withColumn(\"reduced_vector\", to_dense_vector(\"reduced_features\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Failed :PCA Attempts to reduce 63k to 256 parameters"
      ],
      "metadata": {
        "id": "pzgKXOGrMUWT"
      },
      "id": "pzgKXOGrMUWT"
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from pyspark.sql import SparkSession\n",
        "import pandas as pd\n",
        "from pyspark.mllib.linalg.distributed import RowMatrix\n",
        "from pyspark.mllib.linalg import Vectors as MLLibVectors\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"PCA-Cluster-Job\")\\\n",
        "    .getOrCreate()\n",
        "spark.conf.set(\"spark.sql.files.maxPartitionBytes\", 800 * 1024 * 1024)\n",
        "spark.conf.set(\"spark.hadoop.fs.gs.inputstream.buffer.size\", 1048576)\n",
        "\n",
        "features = spark.read.parquet(\"gs://medical-data-for-project/features_subset/\")\n",
        "vector_rdd = features.select(\"features\").rdd.map(lambda row: MLLibVectors.fromML(row[0]))\n",
        "mat = RowMatrix(vector_rdd)\n",
        "pc_matrix = mat.computePrincipalComponents(k=256)\n",
        "\n",
        "\n",
        "# Step 1: Convert to NumPy\n",
        "np_pc = np.array(pc_matrix.toArray())  # shape: (num_features, k)\n",
        "\n",
        "# Step 2: Convert to Pandas DataFrame\n",
        "df_pc = pd.DataFrame(np_pc)\n",
        "\n",
        "# Step 3: Convert to Spark DataFrame\n",
        "spark_df_pc = spark.createDataFrame(df_pc)\n",
        "\n",
        "# Step 4: Save as Parquet to GCS\n",
        "spark_df_pc.write.mode(\"overwrite\").parquet(\"gs://medical-data-for-project/huggingface.co/datasets/vevotx/Tahoe-100M/resolve/main/pca_models/pca_components.parquet\")"
      ],
      "metadata": {
        "id": "R4XTOP29MTst"
      },
      "id": "R4XTOP29MTst",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Failed :PCA Attempt to reduce 63k to 256 parameters, Cluster Job"
      ],
      "metadata": {
        "id": "DZrph7daNPWN"
      },
      "id": "DZrph7daNPWN"
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import udf\n",
        "from pyspark.ml.linalg import SparseVector, VectorUDT\n",
        "from pyspark.ml.feature import PCA\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark import StorageLevel\n",
        "\n",
        "# Initialize Spark session\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"PCA-Cluster-Job\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "# Limit partition size to 800 MB\n",
        "spark.conf.set(\"spark.sql.files.maxPartitionBytes\", 800 * 1024 * 1024)\n",
        "\n",
        "# Optional: enable GCS connector buffering\n",
        "spark.conf.set(\"spark.hadoop.fs.gs.inputstream.buffer.size\", 1048576)\n",
        "\n",
        "# Sparse vector UDF # Major bottleneck in terms of performance,\n",
        "# no alternative available, potentially F.zipwith could be used but did not work\n",
        "# in this case.\n",
        "def make_sparse_vector(genes, expressions):\n",
        "    if not genes or not expressions:\n",
        "        return SparseVector(63000, {})\n",
        "    return SparseVector(63000, dict(zip(genes, expressions)))\n",
        "\n",
        "make_sparse_vector_udf = udf(make_sparse_vector, VectorUDT())\n",
        "\n",
        "# Read data\n",
        "expression_df = spark.read.parquet(\"gs://medical-data-for-project/huggingface.co/datasets/vevotx/Tahoe-100M/resolve/main/data/\") \\\n",
        "    .select(\"sample\", \"drug\", \"cell_line_id\", \"genes\", \"expressions\") \\\n",
        "    .repartition(1500)  # Tune based on cluster\n",
        "\n",
        "cell_line_df = spark.read.parquet(\"gs://medical-data-for-project/huggingface.co/datasets/vevotx/Tahoe-100M/resolve/main/meta_data/cell_line_metadata.parquet\") \\\n",
        "    .select(\"Cell_ID_Cellosaur\")\n",
        "\n",
        "drug_df = spark.read.parquet(\"gs://medical-data-for-project/huggingface.co/datasets/vevotx/Tahoe-100M/resolve/main/meta_data/drug_metadata.parquet\") \\\n",
        "    .select(\"drug\")\n",
        "\n",
        "sample_df = spark.read.parquet(\"gs://medical-data-for-project/huggingface.co/datasets/vevotx/Tahoe-100M/resolve/main/meta_data/sample_metadata.parquet\") \\\n",
        "    .select(\"sample\")\n",
        "\n",
        "cell_line_df = cell_line_df.cache()\n",
        "drug_df = drug_df.cache()\n",
        "sample_df = sample_df.cache()\n",
        "\n",
        "# Join metadata (lazy until actions triggered)\n",
        "df = expression_df.alias(\"expressions\") \\\n",
        "    .join(cell_line_df.alias(\"cell_line\"), expression_df.cell_line_id == cell_line_df.Cell_ID_Cellosaur, \"inner\") \\\n",
        "    .join(sample_df.alias(\"sample\"), \"sample\") \\\n",
        "    .join(drug_df.alias(\"drug\"), \"drug\") \\\n",
        "    .withColumn(\"features\", make_sparse_vector_udf(\"genes\", \"expressions\")) \\\n",
        "    .select(\"features\")\n",
        "\n",
        "df = df.repartition(1500)\n",
        "# Persist transformed data (disk only to avoid memory issues)\n",
        "df = df.persist(StorageLevel.DISK_ONLY)\n",
        "\n",
        "# Run PCA\n",
        "pca = PCA(k=256, inputCol=\"features\", outputCol=\"pca_features\")\n",
        "pca_model = pca.fit(df)\n",
        "\n",
        "# Save model\n",
        "pca_model.save(\"gs://medical-data-for-project/huggingface.co/datasets/vevotx/Tahoe-100M/resolve/main/pca_models/\")\n"
      ],
      "metadata": {
        "id": "WcJPQsL_NN-v"
      },
      "id": "WcJPQsL_NN-v",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "PySpark",
      "language": "python",
      "name": "pyspark"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}